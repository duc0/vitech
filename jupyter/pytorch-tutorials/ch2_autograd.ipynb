{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd: Tính đạo hàm tự động\n",
    "===================================\n",
    "\n",
    "Về mặt toán học thì mạng neural có thể được xem như một hàm toán học phức tạp, và việc tính đạo hàm của nó là rất quan trọng khi huấn luyện mạng neural.\n",
    "\n",
    "Vì vậy ``autograd`` hay chức năng tính đạo hàm tự động là một chức năng vô cùng quan trọng của Pytorch. Nói ngắn gọn, thì ``autograd`` giúp ta tính được giá trị đạo hàm tại các điểm cụ thể với hàm số được tạo ra từ mọi phép toán trên Tensor mà không cần phải biết công thức chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhắc lại về đạo hàm\n",
    "--------\n",
    "\n",
    "Đạo hàm của một hàm số mô tả sự biến thiên của một hàm số tại một điểm, ví dụ \n",
    "cho hàm số $y =3x^2$ thì đạo hàm $y'=6x$.\n",
    "Tại điểm cụ thể $x = 5$, ta có $y = 75$ và $y' = 30$ (giải thích nôm na là, khi x thay đổi 1 đơn vị, thì y thay đổi 30 đơn vị, trong giới hạn nhỏ quanh điểm x=5, ví dụ tạ). Ví dụ tính toán đơn giản này có thể được mô tả trong pytorch như sau:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75.], grad_fn=<ThMulBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo điểm x = 5\n",
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "y = 3 * x * x\n",
    "# Tính y tại điểm x = 5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30.])\n"
     ]
    }
   ],
   "source": [
    "# Tính đạo hàm\n",
    "y.backward()\n",
    "# In ra giá trị đạo hàm y' = dy/dx tại điểm x = 5\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy là pytorch giúp ta tính được giá trị của đạo hàm $y'$ tại một điểm x mà không cần dùng công thức đạo hàm $x^n = nx^{n-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể mở rộng ra việc tính đạo hàm với hàm nhiều biến với ví dụ sau, cho hàm số $z = 5x^3 + 2y^2$, ta có đạo hàm riêng $\\frac{dz}{dx}=15x^2$, và $\\frac{dz}{dy}=4y$. Tại điểm $(x = 7, y = 8)$ ta có $z = 1843$ và $\\frac{dz}{dx}=735$, $\\frac{dz}{dy}=32$\n",
    "\n",
    "Ví dụ này được mô tả trong pytorch như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1843.], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo điểm x = 5\n",
    "x = torch.tensor([7.0], requires_grad=True)\n",
    "y = torch.tensor([8.0], requires_grad=True)\n",
    "z = 5 * x * x * x + 2 * y * y\n",
    "# Tính z tại điểm (x = 7, y = 8)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([735.])\n"
     ]
    }
   ],
   "source": [
    "# Tính đạo hàm\n",
    "z.backward()\n",
    "# In ra giá trị đạo hàm dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32.])\n"
     ]
    }
   ],
   "source": [
    "# In ra giá trị đạo hàm dz/dy\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý trong các ví dụ trên, khi khai báo các tensor như x, y và sau này cần tính đạo hàm, ta cần thêm thuộc tính requires_grad=True để pytorch ghi nhớ các phép toán trên các tensor này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đạo hàm của Tensor\n",
    "--------\n",
    "Ở các ví dụ trên đây, ta đã khai báo x, y như các đại lượng vô hướng (Tensor với kích thước 1), vậy trong trường hợp tổng quát thì sao? Ta hãy quay lại ví dụ đầu tiên nhưng với x là 1 ma trận 2x2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 48.],\n",
      "        [75., 12.]], grad_fn=<ThMulBackward>)\n",
      "tensor([[18., 24.],\n",
      "        [30., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3.0, 4.0], [5.0, 2.0]], requires_grad=True)\n",
    "y = 3 * x * x\n",
    "print(y)\n",
    "y = y.sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý, trong ví dụ trên đây, $x*x$ chỉ phép lấy tích hai ma trận theo từng phân tử, chứ không phải là phép nhân ma trận. Ta thấy trong trường hợp này, kết quả đạo hàm $y'$ chỉ là mở rộng của trường hợp đại lượng vô hướng; mỗi phần tử của $y'$ là giá trị đạo hàm tại điểm tương ứng trên ma trận $x$ ban đầu. Ta hãy thử thay $x*x$ bằng phép nhân ma trận (thể hiện qua hàm torch.mm) và xem giá trị đạo hàm thay đổi như thế nào. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[87., 60.],\n",
      "        [75., 72.]], grad_fn=<MulBackward>)\n",
      "tensor([[45., 45.],\n",
      "        [39., 39.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3.0, 4.0], [5.0, 2.0]], requires_grad=True)\n",
    "y = 3 * torch.mm(x, x)\n",
    "print(y)\n",
    "y = y.sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong ví dụ trên, giả sử\n",
    "$\n",
    "x = \\left(\\begin{array} \n",
    "\\\\a & b\\\\\n",
    "c & d\n",
    "\\end{array}\\right)\n",
    "$, thì ta sẽ có $y = 3 * (a^2 + d^2 + ab + ac + bc + bd + cd)$, và đạo hàm riêng $\\frac{dy}{da}=6a + 3b + 3c$, với $\n",
    "x = \\left(\\begin{array} \n",
    "\\\\3 & 4\\\\\n",
    "5 & 2\n",
    "\\end{array}\\right)\n",
    "$ thì  $\\frac{dy}{da}=45$\n",
    "\n",
    "Ghi chú: ``autograd`` cũng hoạt động được khi y không phải là đại lượng vô hướng; tuy nhiên điều này nằm ngoài phạm vi của bài này."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
